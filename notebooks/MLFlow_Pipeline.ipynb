{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19OHVaGGaws6H9lQ_i40dWgr0ykPQDEs2","authorship_tag":"ABX9TyOzjPMysQmZ3UDBEtnI6rs/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# =============================================================================\n","# 1. IMPORTACIONES\n","# =============================================================================\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","from scipy.stats import randint, uniform\n","\n","# MLflow para seguimiento\n","import mlflow\n","import mlflow.sklearn\n","\n","# Preprocesamiento y Pipeline\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.preprocessing import LabelEncoder, RobustScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Modelos\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","\n","# M√©tricas y Evaluaci√≥n\n","from sklearn.metrics import (\n","    classification_report, confusion_matrix, roc_auc_score,\n","    roc_curve, auc, precision_recall_curve\n",")\n","from sklearn.preprocessing import label_binarize\n","from sklearn.inspection import PartialDependenceDisplay\n","\n","# Ignorar advertencias para una salida m√°s limpia (opcional)\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","# =============================================================================\n","# 2. CLASE DE GESTI√ìN DE DATOS\n","# =============================================================================\n","\n","class DataManager:\n","    \"\"\"\n","    Encapsula la carga, limpieza y preparaci√≥n de los datos.\n","    \"\"\"\n","    def __init__(self, file_path, sep=None):\n","        \"\"\"\n","        Inicializa el gestor de datos.\n","\n","        :param file_path: Ruta al archivo CSV.\n","        :param sep: Separador del CSV (opcional).\n","        \"\"\"\n","        self.file_path = file_path\n","        self.sep = sep\n","        print(f\"DataManager inicializado con el archivo: {file_path}\")\n","\n","    def load_and_clean_data(self):\n","        \"\"\"\n","        Carga el dataset, lo limpia y elimina duplicados y columnas nulas.\n","        \"\"\"\n","        print(\"Iniciando carga y limpieza de datos...\")\n","        # Cargar dataset original\n","        df_raw = pd.read_csv(self.file_path, sep=self.sep, engine=\"python\", encoding=\"utf-8\")\n","        df = df_raw.copy()\n","\n","        # Estandarizar nulos y espacios\n","        df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n","        df = df.replace({\"NA\": np.nan, \"N/A\": np.nan, \"na\": np.nan, \"NaN\": np.nan})\n","\n","        # Recortar strings\n","        obj_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n","        for c in obj_cols:\n","            df[c] = df[c].astype(str).str.strip()\n","\n","        # Eliminar duplicados\n","        duplicates_before = df.duplicated().sum()\n","        df = df.drop_duplicates()\n","        print(f\"Se eliminaron {duplicates_before} duplicados.\")\n","\n","        # Eliminar columnas 100% nulas\n","        all_null = [c for c in df.columns if df[c].isna().all()]\n","        if all_null:\n","            df = df.drop(columns=all_null)\n","            print(f\"Columnas eliminadas (100% nulas): {all_null}\")\n","        else:\n","            print(\"No se encontraron columnas 100% nulas.\")\n","\n","\n","        print(\"Carga y limpieza de datos completada.\")\n","        return df\n","\n","    def split_data(self, df, target_col, test_size=0.2, random_state=42):\n","        \"\"\"\n","        Divide los datos en caracter√≠sticas (X) y objetivo (y),\n","        y luego en conjuntos de entrenamiento y prueba.\n","\n","        :param df: DataFrame limpio.\n","        :param target_col: Nombre de la columna objetivo.\n","        :param test_size: Proporci√≥n del dataset para el conjunto de prueba.\n","        :param random_state: Semilla para reproducibilidad.\n","        :return: X_train, X_test, y_train, y_test\n","        \"\"\"\n","        print(\"Dividiendo datos en entrenamiento y prueba...\")\n","        X = df.drop(target_col, axis=1)\n","        y = df[target_col]\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y, test_size=test_size, random_state=random_state, stratify=y\n","        )\n","        return X_train, X_test, y_train, y_test\n","\n","    def encode_target(self, y_train, y_test):\n","        \"\"\"\n","        Codifica la variable objetivo (y) usando LabelEncoder.\n","\n","        :param y_train: Objetivo de entrenamiento.\n","        :param y_test: Objetivo de prueba.\n","        :return: y_train_encoded, y_test_encoded, label_encoder (el objeto ajustado)\n","        \"\"\"\n","        print(\"Codificando variable objetivo...\")\n","        label_encoder = LabelEncoder()\n","        y_train_encoded = label_encoder.fit_transform(y_train)\n","        y_test_encoded = label_encoder.transform(y_test)\n","        return y_train_encoded, y_test_encoded, label_encoder\n","\n","\n","# =============================================================================\n","# 3. CLASE DE F√ÅBRICA DE PIPELINES\n","# =============================================================================\n","\n","class ModelPipelineFactory:\n","    \"\"\"\n","    Construye y entrena pipelines de modelo con b√∫squeda de hiperpar√°metros.\n","    \"\"\"\n","    def __init__(self):\n","        self.preprocessor = None\n","\n","    def _create_preprocessor(self, X_train):\n","        \"\"\"\n","        Crea un preprocesador (ColumnTransformer) basado en los tipos de\n","        columnas de X_train.\n","\n","        :param X_train: DataFrame de caracter√≠sticas de entrenamiento.\n","        :return: Objeto ColumnTransformer.\n","        \"\"\"\n","        # Identificar tipos de columnas desde X_train\n","        numeric_features = X_train.select_dtypes(include=np.number).columns\n","        categorical_features = X_train.select_dtypes(\n","            include=['object', 'category']\n","        ).columns\n","\n","        print(f\"Preprocesador: {len(numeric_features)} features num√©ricas y {len(categorical_features)} categ√≥ricas.\")\n","\n","        # Pipeline para variables num√©ricas\n","        numeric_transformer = Pipeline(steps=[\n","            ('imputer', SimpleImputer(strategy='constant', fill_value=-20)),\n","            ('scaler', RobustScaler())\n","        ])\n","\n","        # Pipeline para variables categ√≥ricas\n","        categorical_transformer = Pipeline(steps=[\n","            ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n","            ('onehot', OneHotEncoder(\n","                handle_unknown='ignore', sparse_output=False, drop='first'\n","            ))\n","        ])\n","\n","        # Crear el ColumnTransformer\n","        self.preprocessor = ColumnTransformer(transformers=[\n","            ('num', numeric_transformer, numeric_features),\n","            ('cat', categorical_transformer, categorical_features)\n","        ], remainder='passthrough')\n","\n","        return self.preprocessor\n","\n","    def create_and_tune_model(self, X_train, y_train, classifier, param_grid, search_options):\n","        \"\"\"\n","        Crea un pipeline completo y lo entrena usando RandomizedSearchCV.\n","\n","        :param X_train: Caracter√≠sticas de entrenamiento.\n","        :param y_train: Objetivo de entrenamiento (codificado).\n","        :param classifier: El objeto clasificador (ej. XGBClassifier()).\n","        :param param_grid: Diccionario de hiperpar√°metros para la b√∫squeda.\n","        :param search_options: Diccionario de opciones para RandomizedSearchCV.\n","        :return: Objeto RandomizedSearchCV ajustado.\n","        \"\"\"\n","\n","        # 1. Crear el preprocesador si a√∫n no existe\n","        if self.preprocessor is None:\n","            self.preprocessor = self._create_preprocessor(X_train)\n","\n","        # 2. Crear el pipeline principal\n","        model_pipeline = Pipeline(steps=[\n","            ('preprocessor', self.preprocessor),\n","            ('classifier', classifier)\n","        ])\n","\n","        # 3. Configurar y ejecutar la b√∫squeda aleatoria\n","        random_search = RandomizedSearchCV(\n","            model_pipeline,\n","            param_distributions=param_grid,\n","            **search_options  # Desempaqueta n_iter, cv, scoring, etc.\n","        )\n","\n","        model_name = classifier.__class__.__name__\n","        print(f\"Iniciando RandomizedSearchCV para {model_name}...\")\n","        random_search.fit(X_train, y_train)\n","        print(f\"B√∫squeda completada para {model_name}.\")\n","\n","        return random_search\n","\n","\n","# =============================================================================\n","# 4. CLASE DE EVALUACI√ìN DE MODELOS (MODIFICADA PARA MLFLOW)\n","# =============================================================================\n","\n","class ModelEvaluator:\n","    \"\"\"\n","    Encapsula la evaluaci√≥n e interpretaci√≥n de un modelo entrenado.\n","    Modificado para loguear artefactos en MLflow.\n","    \"\"\"\n","    def __init__(self, best_model, X_test, y_test_original, y_test_encoded, label_encoder):\n","        \"\"\"\n","        Inicializa el evaluador con el modelo y los datos de prueba.\n","        \"\"\"\n","        self.model = best_model\n","        self.X_test = X_test\n","        self.y_test_original = y_test_original # 'y_test' (strings)\n","        self.y_test_encoded = y_test_encoded # 'y_test_encoded' (n√∫meros)\n","        self.le = label_encoder\n","        self.class_labels = self.le.classes_\n","        self.model_name = self.model.named_steps['classifier'].__class__.__name__\n","        print(f\"Evaluador listo para el modelo: {self.model_name}\")\n","\n","    def evaluate_classification(self):\n","        \"\"\"\n","        Genera y muestra m√©tricas de evaluaci√≥n, matriz de confusi√≥n y curvas ROC/PR.\n","        Loguea los resultados como texto y figuras en MLflow.\n","        \"\"\"\n","        # Realizar predicciones\n","        y_pred_encoded = self.model.predict(self.X_test)\n","        y_pred_proba = self.model.predict_proba(self.X_test)\n","        y_pred_original = self.le.inverse_transform(y_pred_encoded)\n","\n","        # --- Reporte de Clasificaci√≥n ---\n","        print(\"\\n--- Reporte de Clasificaci√≥n ---\")\n","        reporte_str = classification_report(\n","            self.y_test_original, y_pred_original, target_names=self.class_labels\n","        )\n","        print(reporte_str)\n","        # Loguear reporte como texto en MLflow\n","        mlflow.log_text(reporte_str, \"classification_report.txt\")\n","\n","        # --- Matriz de Confusi√≥n ---\n","        print(\"\\n--- Matriz de Confusi√≥n ---\")\n","        cm = confusion_matrix(self.y_test_original, y_pred_original, labels=self.class_labels)\n","        fig_cm = plt.figure(figsize=(10, 8))\n","        sns.heatmap(\n","            cm, annot=True, fmt='g', cmap='Blues',\n","            xticklabels=self.class_labels, yticklabels=self.class_labels\n","        )\n","        plt.xlabel('Predicci√≥n'); plt.ylabel('Valor Real')\n","        plt.title(f'Matriz de Confusi√≥n - {self.model_name}')\n","        # Loguear figura en MLflow\n","        mlflow.log_figure(fig_cm, \"matriz_confusion.png\")\n","        plt.close(fig_cm) # Cerrar la figura para no mostrarla en el notebook ahora\n","\n","        # --- Curvas ROC y PR ---\n","        y_test_binarized = label_binarize(self.y_test_encoded, classes=range(len(self.class_labels)))\n","        n_classes = y_test_binarized.shape[1]\n","\n","        fig_roc_pr, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","        fig_roc_pr.suptitle(f\"Curvas de Evaluaci√≥n para {self.model_name}\", fontsize=16)\n","\n","        # Curva ROC AUC\n","        try:\n","            roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, multi_class='ovr')\n","            print(f\"\\nROC AUC Score (One-vs-Rest): {roc_auc:.4f}\")\n","            # MLflow autolog() usualmente captura 'roc_auc_score' si se llama\n","            # mlflow.log_metric(\"test_roc_auc_ovr\", roc_auc)\n","            for i in range(n_classes):\n","                fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n","                ax1.plot(fpr, tpr, lw=2, label=f'{self.class_labels[i]} (AUC={auc(fpr, tpr):.2f})')\n","        except ValueError as e:\n","            print(f\"Error al calcular ROC AUC (puede pasar en problemas binarios/formato): {e}\")\n","            ax1.set_title(\"No se pudo generar Curva ROC\")\n","\n","        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n","        ax1.set_xlabel('Tasa de Falsos Positivos (FPR)'); ax1.set_ylabel('Tasa de Verdaderos Positivos (TPR)')\n","        ax1.set_title('Curva ROC Multiclase (One-vs-Rest)'); ax1.legend(loc=\"lower right\"); ax1.grid(True)\n","\n","        # Curva Precisi√≥n-Recall\n","        for i in range(n_classes):\n","            precision, recall, _ = precision_recall_curve(\n","                y_test_binarized[:, i], y_pred_proba[:, i]  # <--- ¬°CORREGIDO!\n","            )\n","            ax2.plot(recall, precision, lw=2, label=f'Clase {self.class_labels[i]}')\n","        ax2.set_xlabel(\"Recall (Sensibilidad)\"); ax2.set_ylabel(\"Precision\")\n","        ax2.set_title(\"Curva Precisi√≥n-Recall Multiclase\"); ax2.legend(loc=\"best\"); ax2.grid(True)\n","        # Loguear figura en MLflow\n","        mlflow.log_figure(fig_roc_pr, \"curvas_roc_pr.png\")\n","        plt.close(fig_roc_pr)\n","\n","    def plot_feature_importance(self, X_train):\n","        \"\"\"\n","        Calcula y grafica la importancia de las variables del modelo.\n","        Loguea la figura en MLflow.\n","        \"\"\"\n","        if not hasattr(self.model.named_steps['classifier'], 'feature_importances_'):\n","            print(f\"\\nEl modelo seleccionado ({self.model_name}) no tiene 'feature_importances_'.\")\n","            return\n","\n","        print(\"\\n--- Importancia de Variables ---\")\n","        model = self.model.named_steps['classifier']\n","        preprocessor = self.model.named_steps['preprocessor']\n","\n","        try:\n","            # Obtener nombres de features del preprocesador\n","            numeric_features = X_train.select_dtypes(include=np.number).columns\n","            cat_features = X_train.select_dtypes(include=['object', 'category']).columns\n","            ohe_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_features)\n","            all_features = np.concatenate([numeric_features, ohe_features])\n","\n","            importances_df = pd.DataFrame({\n","                'feature': all_features,\n","                'importance': model.feature_importances_\n","            }).sort_values(by='importance', ascending=False)\n","\n","            fig_fi = plt.figure(figsize=(12, 10))\n","            sns.barplot(x='importance', y='feature', data=importances_df.head(20), palette='viridis')\n","            plt.title(f'Top 20 Variables Importantes ({self.model_name})', fontsize=16)\n","            plt.xlabel('Importancia'); plt.ylabel('Variable'); plt.grid(axis='x', alpha=0.5)\n","            # Loguear figura en MLflow\n","            mlflow.log_figure(fig_fi, \"importancia_variables.png\")\n","            plt.close(fig_fi)\n","\n","        except Exception as e:\n","            print(f\"Error al calcular feature importance: {e}\")\n","\n","    def plot_partial_dependence(self, X_train, features_to_plot):\n","        \"\"\"\n","        Genera y muestra las curvas de dependencia parcial (PDP) para las\n","        variables especificadas. Loguea las figuras en MLflow.\n","\n","        :param X_train: DataFrame de entrenamiento.\n","        :param features_to_plot: Lista de nombres de columnas a graficar.\n","        \"\"\"\n","        print(f\"\\n--- Generando Curvas de Dependencia Parcial para: {features_to_plot} ---\")\n","\n","        for feature in features_to_plot:\n","            n_classes = len(self.class_labels)\n","            n_cols = 3\n","            n_rows = math.ceil(n_classes / n_cols)\n","            fig_pdp, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows), sharey=True)\n","            fig_pdp.suptitle(f'Dependencia Parcial de \"{feature}\" ({self.model_name})', fontsize=16, y=1.02)\n","\n","            for i, class_name in enumerate(self.class_labels):\n","                ax = axes.flatten()[i]\n","                try:\n","                    PartialDependenceDisplay.from_estimator(\n","                        self.model,\n","                        X_train,\n","                        features=[feature],\n","                        target=i,\n","                        ax=ax\n","                    )\n","                    ax.set_title(f'Target: {class_name}')\n","                    ax.set_xlabel(feature)\n","                    ax.set_ylabel(\"Dependencia Parcial\")\n","                except Exception as e:\n","                    print(f\"Error al generar PDP para {feature}, clase {class_name}: {e}\")\n","                    ax.set_title(f'Error al generar PDP para {class_name}')\n","                    ax.axis('off')\n","\n","            # Ocultar ejes no utilizados\n","            for j in range(n_classes, len(axes.flatten())):\n","                axes.flatten()[j].axis('off')\n","\n","            plt.tight_layout()\n","            plt.subplots_adjust(top=0.92)\n","            # Loguear figura en MLflow\n","            mlflow.log_figure(fig_pdp, f\"pdp_{feature}.png\")\n","            plt.close(fig_pdp)\n","\n","\n","# =============================================================================\n","# 5. BLOQUE PRINCIPAL DE EJECUCI√ìN (MODIFICADO PARA MLFLOW)\n","# =============================================================================\n","\n","def define_models_to_train():\n","    \"\"\"\n","    Define la configuraci√≥n de los modelos y sus hiperpar√°metros.\n","    Separar esto como una funci√≥n mantiene limpio el bloque principal.\n","    \"\"\"\n","\n","    models_config = [\n","        {\n","            \"name\": \"KNN\",\n","            \"classifier\": KNeighborsClassifier(),\n","            \"param_grid\": {\n","                'classifier__n_neighbors': randint(3, 31),\n","                'classifier__weights': ['uniform', 'distance'],\n","                'classifier__metric': ['euclidean', 'manhattan', 'minkowski'],\n","            }\n","        },\n","        {\n","            \"name\": \"Random Forest\",\n","            \"classifier\": RandomForestClassifier(random_state=42),\n","            \"param_grid\": {\n","                'classifier__n_estimators': randint(100, 500),\n","                'classifier__max_depth': randint(5, 30),\n","                'classifier__min_samples_split': randint(2, 20),\n","                'classifier__min_samples_leaf': randint(1, 20),\n","                'classifier__max_features': ['sqrt', 'log2'],\n","            }\n","        },\n","        {\n","            \"name\": \"XGBoost\",\n","            \"classifier\": XGBClassifier(\n","                objective='multi:softmax', eval_metric='mlogloss',\n","                use_label_encoder=False, random_state=42\n","            ),\n","            \"param_grid\": {\n","                'classifier__n_estimators': randint(100, 500),\n","                'classifier__max_depth': randint(3, 10),\n","                'classifier__learning_rate': uniform(0.01, 0.3),\n","                'classifier__subsample': uniform(0.6, 0.4),\n","                'classifier__colsample_bytree': uniform(0.6, 0.4),\n","            }\n","        }\n","    ]\n","    return models_config\n","\n"],"metadata":{"id":"eH3VkYCKXYcj","executionInfo":{"status":"ok","timestamp":1762100408746,"user_tz":300,"elapsed":87,"user":{"displayName":"Daniel Camilo Vargas Sandoval","userId":"08538069732530044949"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    # --- 1. Configuraci√≥n Inicial ---\n","    SRC_PATH = '/content/drive/MyDrive/Pregrado - Posgrado - Trabajo/Maestr√≠a - Inteligencia Artificial Aplicada/11. MLOps/1. Primera etapa de proyecto/Modelado/obesity_estimation_original.csv'\n","    TARGET = 'NObeyesdad'\n","\n","    print(\"Iniciando Proceso de ML Completo...\")\n","\n","    # --- 2. Preparaci√≥n de Datos ---\n","    # Instanciar y usar el DataManager\n","    data_manager = DataManager(file_path=SRC_PATH)\n","    df_cleaned = data_manager.load_and_clean_data()\n","\n","    X_train, X_test, y_train, y_test = data_manager.split_data(\n","        df_cleaned, TARGET, test_size=0.2, random_state=42\n","    )\n","\n","    y_train_encoded, y_test_encoded, label_encoder = data_manager.encode_target(\n","        y_train, y_test\n","    )\n","\n","    # --- 3. Configuraci√≥n de Entrenamiento ---\n","    models_config = define_models_to_train()\n","    factory = ModelPipelineFactory()\n","\n","    # Opciones comunes para RandomizedSearchCV\n","    SEARCH_OPTIONS = {\n","        'n_iter': 50,      # N√∫mero de iteraciones\n","        'cv': 5,           # N√∫mero de folds de validaci√≥n cruzada\n","        'scoring': 'accuracy',\n","        'verbose': 1,\n","        'random_state': 42,\n","        'n_jobs': -1       # Usar todos los n√∫cleos de CPU disponibles\n","    }\n","\n","    # --- 3b. Configuraci√≥n de MLflow ---\n","    mlflow.set_experiment(\"Pipeline_Modelado_Obesidad\")\n","    # Activar autologging para m√©tricas, par√°metros, y el modelo de sklearn\n","    mlflow.sklearn.autolog(\n","        log_models=True,\n","        log_input_examples=True,\n","        log_model_signatures=True,\n","        log_datasets=False,\n","        disable=False,\n","        exclusive=False,\n","        log_post_training_metrics=True # Asegura que m√©tricas post-fit se logueen\n","    )\n","    print(\"MLflow configurado y autologging de sklearn activado.\")\n","\n","    # --- 4. Bucle de Entrenamiento y Evaluaci√≥n con MLflow ---\n","    for config in models_config:\n","        model_name = config[\"name\"]\n","        print(\"=\"*80)\n","        print(f\" INICIANDO ENTRENAMIENTO PARA: {model_name}\")\n","        print(\"=\"*80)\n","\n","        # Envolver cada modelo en un run de MLflow\n","        with mlflow.start_run(run_name=model_name) as run:\n","\n","            # Entrenar el modelo usando la f√°brica\n","            # autolog() registrar√° los par√°metros de search_cv y las m√©tricas de CV\n","            search_cv = factory.create_and_tune_model(\n","                X_train,\n","                y_train_encoded,\n","                config[\"classifier\"],\n","                config[\"param_grid\"],\n","                SEARCH_OPTIONS\n","            )\n","\n","            best_model = search_cv.best_estimator_\n","\n","            # --- 5. Resultados y Evaluaci√≥n ---\n","            print(\"\\n\" + f\"--- RESULTADOS FINALES: {model_name} ---\")\n","            print(f\"Mejores Hiperpar√°metros (autologged por sklearn):\")\n","            print(search_cv.best_params_)\n","            print(f\"\\nMejor puntaje CV (Accuracy) (autologged): {search_cv.best_score_:.4f}\")\n","\n","            # autolog() de sklearn registra .score() autom√°ticamente\n","            accuracy_test = best_model.score(X_test, y_test_encoded)\n","            print(f\"Precisi√≥n final en Test (autologged): {accuracy_test:.4f}\\n\")\n","\n","            # Loguear expl√≠citamente para asegurar (aunque autolog deber√≠a tomarlo)\n","            mlflow.log_metric(\"final_test_accuracy\", accuracy_test)\n","            mlflow.set_tag(\"model_type\", model_name)\n","\n","            # Instanciar y usar el ModelEvaluator\n","            # Las modificaciones en la clase loguear√°n las figuras y reportes\n","            evaluator = ModelEvaluator(\n","                best_model, X_test, y_test, y_test_encoded, label_encoder\n","            )\n","\n","            print(\"\\n--- EVALUACI√ìN DETALLADA EN TEST (Logueando artefactos) ---\")\n","            evaluator.evaluate_classification()\n","\n","            print(\"\\n--- INTERPRETACI√ìN DEL MODELO (Logueando artefactos) ---\")\n","            # autolog() tambi√©n intenta loguear feature importance, pero lo hacemos\n","            # manualmente para asegurar que usemos nuestros nombres de features preprocesadas.\n","            evaluator.plot_feature_importance(X_train)\n","\n","            # L√≥gica espec√≠fica para PDP (Logueando artefactos)\n","            if model_name == \"XGBoost\":\n","                print('Generando gr√°ficos de Dependencia Parcial (PDP) para XGBoost...')\n","                features_for_pdp = X_train.select_dtypes(include=np.number).columns.tolist()\n","                if features_for_pdp:\n","                     evaluator.plot_partial_dependence(X_train, features_for_pdp[:3])\n","                else:\n","                    print(\"No se encontraron features num√©ricas para PDP.\")\n","\n","            print(f\"\\nRun ID para {model_name}: {run.info.run_id}\")\n","\n","    print(\"=\"*80)\n","    print(\"Proceso de ML Completo Finalizado.\")\n","    print(\"=\"*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PW6lIrUXXjX8","executionInfo":{"status":"ok","timestamp":1762101179358,"user_tz":300,"elapsed":770590,"user":{"displayName":"Daniel Camilo Vargas Sandoval","userId":"08538069732530044949"}},"outputId":"e24a2b30-9ad3-403a-8cb6-e4fe499af19b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Iniciando Proceso de ML Completo...\n","DataManager inicializado con el archivo: /content/drive/MyDrive/Pregrado - Posgrado - Trabajo/Maestr√≠a - Inteligencia Artificial Aplicada/11. MLOps/1. Primera etapa de proyecto/Modelado/obesity_estimation_original.csv\n","Iniciando carga y limpieza de datos...\n","Se eliminaron 24 duplicados.\n","No se encontraron columnas 100% nulas.\n","Carga y limpieza de datos completada.\n","Dividiendo datos en entrenamiento y prueba...\n","Codificando variable objetivo...\n","MLflow configurado y autologging de sklearn activado.\n","================================================================================\n"," INICIANDO ENTRENAMIENTO PARA: KNN\n","================================================================================\n","Preprocesador: 8 features num√©ricas y 8 categ√≥ricas.\n","Iniciando RandomizedSearchCV para KNeighborsClassifier...\n","Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"]},{"output_type":"stream","name":"stderr","text":["2025/11/02 16:20:37 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"]},{"output_type":"stream","name":"stdout","text":["B√∫squeda completada para KNeighborsClassifier.\n","\n","--- RESULTADOS FINALES: KNN ---\n","Mejores Hiperpar√°metros (autologged por sklearn):\n","{'classifier__metric': 'manhattan', 'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}\n","\n","Mejor puntaje CV (Accuracy) (autologged): 0.8610\n","Precisi√≥n final en Test (autologged): 0.8612\n","\n","Evaluador listo para el modelo: KNeighborsClassifier\n","\n","--- EVALUACI√ìN DETALLADA EN TEST (Logueando artefactos) ---\n","\n","--- Reporte de Clasificaci√≥n ---\n","                     precision    recall  f1-score   support\n","\n","Insufficient_Weight       0.82      0.94      0.88        53\n","      Normal_Weight       0.69      0.54      0.61        57\n","     Obesity_Type_I       0.86      0.93      0.89        70\n","    Obesity_Type_II       1.00      1.00      1.00        60\n","   Obesity_Type_III       0.98      1.00      0.99        65\n"," Overweight_Level_I       0.74      0.78      0.76        55\n","Overweight_Level_II       0.88      0.79      0.84        58\n","\n","           accuracy                           0.86       418\n","          macro avg       0.85      0.86      0.85       418\n","       weighted avg       0.86      0.86      0.86       418\n","\n","\n","--- Matriz de Confusi√≥n ---\n","\n","ROC AUC Score (One-vs-Rest): 0.9605\n","\n","--- INTERPRETACI√ìN DEL MODELO (Logueando artefactos) ---\n","\n","El modelo seleccionado (KNeighborsClassifier) no tiene 'feature_importances_'.\n","\n","Run ID para KNN: 449771479ac7438a86d4cafecbc6f8ed\n","================================================================================\n"," INICIANDO ENTRENAMIENTO PARA: Random Forest\n","================================================================================\n","Iniciando RandomizedSearchCV para RandomForestClassifier...\n","Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"]},{"output_type":"stream","name":"stderr","text":["2025/11/02 16:25:51 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"]},{"output_type":"stream","name":"stdout","text":["B√∫squeda completada para RandomForestClassifier.\n","\n","--- RESULTADOS FINALES: Random Forest ---\n","Mejores Hiperpar√°metros (autologged por sklearn):\n","{'classifier__max_depth': 21, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 323}\n","\n","Mejor puntaje CV (Accuracy) (autologged): 0.9377\n","Precisi√≥n final en Test (autologged): 0.9498\n","\n","Evaluador listo para el modelo: RandomForestClassifier\n","\n","--- EVALUACI√ìN DETALLADA EN TEST (Logueando artefactos) ---\n","\n","--- Reporte de Clasificaci√≥n ---\n","                     precision    recall  f1-score   support\n","\n","Insufficient_Weight       1.00      0.94      0.97        53\n","      Normal_Weight       0.79      0.95      0.86        57\n","     Obesity_Type_I       1.00      0.97      0.99        70\n","    Obesity_Type_II       1.00      1.00      1.00        60\n","   Obesity_Type_III       1.00      0.98      0.99        65\n"," Overweight_Level_I       0.91      0.89      0.90        55\n","Overweight_Level_II       0.96      0.90      0.93        58\n","\n","           accuracy                           0.95       418\n","          macro avg       0.95      0.95      0.95       418\n","       weighted avg       0.95      0.95      0.95       418\n","\n","\n","--- Matriz de Confusi√≥n ---\n","\n","ROC AUC Score (One-vs-Rest): 0.9940\n","\n","--- INTERPRETACI√ìN DEL MODELO (Logueando artefactos) ---\n","\n","--- Importancia de Variables ---\n","\n","Run ID para Random Forest: 395bc619a3e64d20ac6a32676bd64c68\n","================================================================================\n"," INICIANDO ENTRENAMIENTO PARA: XGBoost\n","================================================================================\n","Iniciando RandomizedSearchCV para XGBClassifier...\n","Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"]},{"output_type":"stream","name":"stderr","text":["2025/11/02 16:30:25 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"]},{"output_type":"stream","name":"stdout","text":["B√∫squeda completada para XGBClassifier.\n","\n","--- RESULTADOS FINALES: XGBoost ---\n","Mejores Hiperpar√°metros (autologged por sklearn):\n","{'classifier__colsample_bytree': np.float64(0.9521871356061031), 'classifier__learning_rate': np.float64(0.197306214440138), 'classifier__max_depth': 8, 'classifier__n_estimators': 233, 'classifier__subsample': np.float64(0.782613828193164)}\n","\n","Mejor puntaje CV (Accuracy) (autologged): 0.9670\n","Precisi√≥n final en Test (autologged): 0.9737\n","\n","Evaluador listo para el modelo: XGBClassifier\n","\n","--- EVALUACI√ìN DETALLADA EN TEST (Logueando artefactos) ---\n","\n","--- Reporte de Clasificaci√≥n ---\n","                     precision    recall  f1-score   support\n","\n","Insufficient_Weight       1.00      1.00      1.00        53\n","      Normal_Weight       0.93      0.95      0.94        57\n","     Obesity_Type_I       1.00      0.97      0.99        70\n","    Obesity_Type_II       0.97      1.00      0.98        60\n","   Obesity_Type_III       1.00      0.98      0.99        65\n"," Overweight_Level_I       0.94      0.93      0.94        55\n","Overweight_Level_II       0.97      0.98      0.97        58\n","\n","           accuracy                           0.97       418\n","          macro avg       0.97      0.97      0.97       418\n","       weighted avg       0.97      0.97      0.97       418\n","\n","\n","--- Matriz de Confusi√≥n ---\n","\n","ROC AUC Score (One-vs-Rest): 0.9995\n","\n","--- INTERPRETACI√ìN DEL MODELO (Logueando artefactos) ---\n","\n","--- Importancia de Variables ---\n","Generando gr√°ficos de Dependencia Parcial (PDP) para XGBoost...\n","\n","--- Generando Curvas de Dependencia Parcial para: ['Age', 'Height', 'Weight'] ---\n","\n","Run ID para XGBoost: 82c16bb4c9d1485cbb595a6f40825900\n","================================================================================\n","Proceso de ML Completo Finalizado.\n","================================================================================\n"]}]},{"cell_type":"code","source":["# --------------------------------------------------------------------------\n","# CONFIGURACI√ìN\n","# --------------------------------------------------------------------------\n","\n","# 1. Escribe el nombre EXACTO de tu experimento\n","EXPERIMENT_NAME = \"Pipeline_Modelado_Obesidad\"\n","\n","# 2. Escribe la m√©trica EXACTA que quieres usar para comparar\n","#    (Debe empezar con \"metrics.\" seguido del nombre de la m√©trica)\n","#    En tu c√≥digo, guardaste la m√©trica de test como \"final_test_accuracy\"\n","METRIC_TO_OPTIMIZE = \"metrics.final_test_accuracy\"\n","\n","# 3. Define si quieres el valor m√°s alto (DESC) o m√°s bajo (ASC)\n","#    Para 'accuracy' o 'AUC', usamos 'DESC' (descendente)\n","#    Para 'loss' o 'error', usar√≠amos 'ASC' (ascendente)\n","SORT_ORDER = \"DESC\"\n","\n","# --------------------------------------------------------------------------\n","# B√öSQUEDA DEL MEJOR RUN\n","# --------------------------------------------------------------------------\n","\n","print(f\"Buscando el mejor 'Run' en el experimento: '{EXPERIMENT_NAME}'\")\n","print(f\"Optimizando para la m√©trica: {METRIC_TO_OPTIMIZE}\\n\")\n","\n","try:\n","    # 4. Cargar el experimento\n","    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n","    if experiment is None:\n","        raise mlflow.exceptions.MlflowException(f\"No se encontr√≥ el experimento '{EXPERIMENT_NAME}'\")\n","\n","    experiment_id = experiment.experiment_id\n","\n","    # 5. Usar search_runs para obtener TODOS los runs en un DataFrame\n","    #    Ordenamos los resultados por la m√©trica deseada\n","    runs_df = mlflow.search_runs(\n","        experiment_ids=[experiment_id],\n","        order_by=[f\"{METRIC_TO_OPTIMIZE} {SORT_ORDER}\"]\n","    )\n","\n","    if runs_df.empty:\n","        print(\"No se encontraron 'Runs' en este experimento.\")\n","    else:\n","        # 6. El mejor run es la primera fila (fila 0)\n","        best_run = runs_df.iloc[0]\n","\n","        print(\"--- üèÜ ¬°MEJOR RUN ENCONTRADO! üèÜ ---\")\n","        print(f\"Modelo (Run Name): {best_run['tags.mlflow.runName']}\")\n","        print(f\"Run ID:            {best_run.run_id}\")\n","        print(f\"M√©trica ({METRIC_TO_OPTIMIZE}): {best_run[METRIC_TO_OPTIMIZE]:.4f}\")\n","\n","        # 7. Mostrar los hiperpar√°metros de ese mejor run\n","        print(\"\\n--- Hiperpar√°metros del Mejor Run ---\")\n","        # Filtra todas las columnas que empiezan con \"params.\"\n","        param_cols = [col for col in best_run.index if col.startswith('params.')]\n","\n","        # Imprime cada par√°metro\n","        for param in param_cols:\n","            param_name = param.replace('params.', '') # Nombre limpio\n","            param_value = best_run[param]\n","            print(f\"{param_name}: {param_value}\")\n","\n","        # 8. Mostrar d√≥nde est√°n los artefactos (el modelo guardado y las gr√°ficas)\n","        print(\"\\n--- Ubicaci√≥n de Artefactos (Modelo y Gr√°ficas) ---\")\n","        # El artifact_uri puede ser una ruta local o una ruta en la nube (S3, etc.)\n","        print(f\"Ruta: {best_run.artifact_uri}\")\n","\n","\n","except mlflow.exceptions.MlflowException as e:\n","    print(f\"ERROR: No se pudo conectar o encontrar el experimento.\")\n","    print(f\"Aseg√∫rate de que el nombre '{EXPERIMENT_NAME}' es correcto.\")\n","    print(f\"Detalle del error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSrSSyn6S06U","executionInfo":{"status":"ok","timestamp":1762101179661,"user_tz":300,"elapsed":314,"user":{"displayName":"Daniel Camilo Vargas Sandoval","userId":"08538069732530044949"}},"outputId":"85921bda-dbb5-48ed-ee58-a276cffa0f65"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Buscando el mejor 'Run' en el experimento: 'Pipeline_Modelado_Obesidad'\n","Optimizando para la m√©trica: metrics.final_test_accuracy\n","\n","--- üèÜ ¬°MEJOR RUN ENCONTRADO! üèÜ ---\n","Modelo (Run Name): XGBoost\n","Run ID:            82c16bb4c9d1485cbb595a6f40825900\n","M√©trica (metrics.final_test_accuracy): 0.9737\n","\n","--- Hiperpar√°metros del Mejor Run ---\n","best_classifier__max_depth: 8\n","scoring: accuracy\n","random_state: 42\n","best_classifier__colsample_bytree: 0.9521871356061031\n","refit: True\n","param_distributions: {'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7b291994b080>, 'classifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7b28ecdc6630>, 'classifier__learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7b291994cec0>, 'classifier__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7b291994cd10>, 'classifier__colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7b291994c710>}\n","n_jobs: -1\n","cv: 5\n","error_score: nan\n","pre_dispatch: 2*n_jobs\n","verbose: 1\n","estimator: Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(remainder='passthrough',\n","                                   transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(fill_value=-20,\n","                                                                                 strategy='constant')),\n","                                                                  ('scaler',\n","                                                                   RobustScaler())]),\n","                                                  Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE'], dtype='object')),\n","                                                 ('cat',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(fill_value='Missing'...\n","                               feature_types=None, feature_weights=None,\n","                               gamma=None, grow_policy=None,\n","                               importance_type=None,\n","                               interaction_constraints=None, learning_rate=None,\n","                               max_bin=None, max_cat_threshold=None,\n","                               max_cat_to_onehot=None, max_delta_step=None,\n","                               max_depth=None, max_leaves=None,\n","                               min_child_weight=None, missing=nan,\n","                               monotone_constraints=None, multi_strategy=None,\n","                               n_estimators=None, n_jobs=None,\n","                               num_parallel_tree=None, ...))])\n","best_classifier__subsample: 0.782613828193164\n","return_train_score: False\n","n_iter: 50\n","best_classifier__n_estimators: 233\n","best_classifier__learning_rate: 0.197306214440138\n","best_classifier__min_samples_split: None\n","best_classifier__min_samples_leaf: None\n","best_classifier__max_features: None\n","best_classifier__metric: None\n","best_classifier__n_neighbors: None\n","best_classifier__weights: None\n","preprocessor__force_int_remainder_cols: None\n","preprocessor__verbose_feature_names_out: None\n","preprocessor__num__scaler: None\n","preprocessor__num: None\n","preprocessor__cat__onehot__min_frequency: None\n","classifier__colsample_bytree: None\n","preprocessor__cat__onehot__drop: None\n","preprocessor__num__imputer__copy: None\n","preprocessor__cat__onehot__feature_name_combiner: None\n","preprocessor: None\n","preprocessor__cat__steps: None\n","classifier__tree_method: None\n","classifier__feature_types: None\n","classifier__scale_pos_weight: None\n","preprocessor__cat__imputer__add_indicator: None\n","classifier__random_state: None\n","preprocessor__cat__imputer__keep_empty_features: None\n","classifier__max_cat_to_onehot: None\n","preprocessor__cat__onehot: None\n","preprocessor__cat__onehot__categories: None\n","classifier__verbosity: None\n","classifier__max_delta_step: None\n","classifier__n_estimators: None\n","preprocessor__num__scaler__with_scaling: None\n","preprocessor__cat__imputer__strategy: None\n","classifier__max_leaves: None\n","preprocessor__cat__imputer__missing_values: None\n","steps: None\n","classifier__base_score: None\n","classifier__min_child_weight: None\n","memory: None\n","classifier__gamma: None\n","preprocessor__cat__onehot__dtype: None\n","preprocessor__num__verbose: None\n","classifier__max_cat_threshold: None\n","preprocessor__num__steps: None\n","preprocessor__transformers: None\n","preprocessor__cat__imputer__copy: None\n","preprocessor__sparse_threshold: None\n","preprocessor__cat__onehot__sparse_output: None\n","classifier__max_bin: None\n","preprocessor__num__scaler__quantile_range: None\n","classifier__multi_strategy: None\n","classifier__use_label_encoder: None\n","transform_input: None\n","classifier__learning_rate: None\n","preprocessor__transformer_weights: None\n","preprocessor__cat__verbose: None\n","classifier__num_parallel_tree: None\n","preprocessor__verbose: None\n","classifier__missing: None\n","classifier__monotone_constraints: None\n","classifier__max_depth: None\n","preprocessor__cat__transform_input: None\n","classifier__sampling_method: None\n","preprocessor__num__scaler__unit_variance: None\n","classifier__grow_policy: None\n","classifier__reg_alpha: None\n","classifier__interaction_constraints: None\n","classifier__validate_parameters: None\n","preprocessor__num__scaler__copy: None\n","classifier__subsample: None\n","classifier__booster: None\n","preprocessor__num__imputer__missing_values: None\n","preprocessor__num__imputer__fill_value: None\n","preprocessor__cat__memory: None\n","preprocessor__num__imputer__strategy: None\n","classifier__importance_type: None\n","classifier__n_jobs: None\n","classifier__colsample_bylevel: None\n","classifier__early_stopping_rounds: None\n","preprocessor__num__imputer__keep_empty_features: None\n","preprocessor__num__imputer: None\n","preprocessor__remainder: None\n","preprocessor__num__scaler__with_centering: None\n","preprocessor__cat__onehot__handle_unknown: None\n","preprocessor__num__memory: None\n","classifier__reg_lambda: None\n","preprocessor__num__imputer__add_indicator: None\n","classifier__objective: None\n","preprocessor__cat__onehot__max_categories: None\n","preprocessor__n_jobs: None\n","classifier: None\n","preprocessor__cat__imputer__fill_value: None\n","classifier__callbacks: None\n","preprocessor__cat: None\n","classifier__enable_categorical: None\n","classifier__device: None\n","preprocessor__num__transform_input: None\n","preprocessor__cat__imputer: None\n","classifier__eval_metric: None\n","classifier__colsample_bynode: None\n","classifier__feature_weights: None\n","classifier__min_samples_leaf: None\n","classifier__max_samples: None\n","classifier__warm_start: None\n","classifier__oob_score: None\n","classifier__class_weight: None\n","classifier__min_weight_fraction_leaf: None\n","classifier__monotonic_cst: None\n","classifier__max_features: None\n","classifier__verbose: None\n","classifier__criterion: None\n","classifier__max_leaf_nodes: None\n","classifier__min_samples_split: None\n","classifier__ccp_alpha: None\n","classifier__min_impurity_decrease: None\n","classifier__bootstrap: None\n","classifier__leaf_size: None\n","classifier__p: None\n","classifier__algorithm: None\n","classifier__metric: None\n","classifier__metric_params: None\n","classifier__n_neighbors: None\n","classifier__weights: None\n","\n","--- Ubicaci√≥n de Artefactos (Modelo y Gr√°ficas) ---\n","Ruta: file:///content/mlruns/647562631659939580/82c16bb4c9d1485cbb595a6f40825900/artifacts\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V1uI0haSVEYS","executionInfo":{"status":"ok","timestamp":1762101179663,"user_tz":300,"elapsed":1,"user":{"displayName":"Daniel Camilo Vargas Sandoval","userId":"08538069732530044949"}}},"execution_count":7,"outputs":[]}]}